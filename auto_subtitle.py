import requests
import json
import os
import argparse
import time
import hashlib
import urllib.parse
import qrcode
from pathlib import Path
from typing import Optional, Tuple, Dict, List, Any

# ==============================================================================
# BiliBiliSession: å°†å›ºå®šçš„ HEADERS å’Œ cookie ç®¡ç†å°è£…åˆ° Session ç±»ä¸­
# ==============================================================================

class BiliAuthError(Exception):
    """è‡ªå®šä¹‰Bç«™ç™»å½•è®¤è¯å¼‚å¸¸"""
    pass

class BiliBiliSession:
    """
    ç”¨äºç®¡ç†Bç«™è¯·æ±‚ä¼šè¯ã€CookieåŠ è½½å’Œæ‰«ç ç™»å½•çš„ç±»ã€‚
    """
    BASE_DIR = Path(__file__).resolve().parent
    COOKIE_FILE = BASE_DIR / "cookie.json"  # ä½¿ç”¨.jsonå­˜å‚¨æ›´ç»“æ„åŒ–

    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            "User-Agent": (
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                "AppleWebKit/537.36 (KHTML, like Gecko) "
                "Chrome/114.0.0.0 Safari/537.36"
            ),
            "Referer": "https://www.bilibili.com/",
        })
        self.csrf = ""
        self.load_cookie()

    def load_cookie(self):
        """ä» cookie.json åŠ è½½ cookie å¹¶éªŒè¯å…¶æœ‰æ•ˆæ€§"""
        if not self.COOKIE_FILE.exists():
            print("â„¹ï¸ æœªæ‰¾åˆ°æœ¬åœ° cookie æ–‡ä»¶, å°†å°è¯•æ‰«ç ç™»å½•ã€‚")
            self.login_by_qrcode()
            return

        try:
            with open(self.COOKIE_FILE, "r", encoding="utf-8") as f:
                cookies = json.load(f)
            
            # æå–å…³é”® cookie
            sessdata = cookies.get("SESSDATA")
            self.csrf = cookies.get("bili_jct")
            
            if not sessdata or not self.csrf:
                raise ValueError("Cookie æ–‡ä»¶ä¸­ç¼ºå°‘å…³é”®å­—æ®µ SESSDATA æˆ– bili_jct")

            self.session.cookies.update({"SESSDATA": sessdata, "bili_jct": self.csrf})
            
            # é€šè¿‡è®¿é—®ä¸€ä¸ªéœ€è¦ç™»å½•çš„æ¥å£æ¥éªŒè¯ cookie æ˜¯å¦æœ‰æ•ˆ
            if not self.check_login_status():
                 print("âš ï¸ Cookie å·²å¤±æ•ˆ, è¯·é‡æ–°æ‰«ç ç™»å½•ã€‚")
                 self.login_by_qrcode()
            else:
                print("âœ… å·²æˆåŠŸåŠ è½½æœ¬åœ° Cookie, ç™»å½•çŠ¶æ€æœ‰æ•ˆã€‚")

        except (json.JSONDecodeError, ValueError) as e:
            print(f"âŒ åŠ è½½ Cookie å¤±è´¥: {e}ã€‚å°†å°è¯•æ‰«ç ç™»å½•ã€‚")
            self.login_by_qrcode()

    def check_login_status(self) -> bool:
        """æ£€æŸ¥å½“å‰ç™»å½•çŠ¶æ€æ˜¯å¦æœ‰æ•ˆ"""
        url = "https://api.bilibili.com/x/web-interface/nav"
        try:
            resp = self.session.get(url, timeout=5)
            resp.raise_for_status()
            data = resp.json()
            return data.get("code") == 0 and data.get("data", {}).get("isLogin", False)
        except requests.RequestException:
            return False

    def save_cookie(self):
        """å°†ä¼šè¯ä¸­çš„ cookie ä¿å­˜åˆ°æ–‡ä»¶"""
        cookies = {
            "SESSDATA": self.session.cookies.get("SESSDATA"),
            "bili_jct": self.session.cookies.get("bili_jct"),
            "DedeUserID": self.session.cookies.get("DedeUserID"),
        }
        with open(self.COOKIE_FILE, "w", encoding="utf-8") as f:
            json.dump(cookies, f, indent=4)
        print(f"ğŸ’¾ Cookie å·²ä¿å­˜è‡³: {self.COOKIE_FILE}")

    def login_by_qrcode(self):
        """é€šè¿‡äºŒç»´ç æ‰«æè¿›è¡Œç™»å½•"""
        print("ğŸš€ æ­£åœ¨ç”Ÿæˆç™»å½•äºŒç»´ç ...")
        # 1. è·å–äºŒç»´ç åŠ qrcode_key
        get_qrcode_url = "https://passport.bilibili.com/x/passport-login/web/qrcode/generate"
        resp = self.session.get(get_qrcode_url)
        data = resp.json()["data"]
        qrcode_key = data["qrcode_key"]
        qr_url = data["url"]

        # 2. åœ¨ç»ˆç«¯æ˜¾ç¤ºäºŒç»´ç 
        qr = qrcode.QRCode()
        qr.add_data(qr_url)
        qr.make(fit=True)
        # ä½¿ç”¨invertå‚æ•°è®©äºŒç»´ç åœ¨æ·±è‰²èƒŒæ™¯ç»ˆç«¯æ›´å¥½çœ‹
        qr.print_tty(invert=True) # ä½¿ç”¨ tty æ¨¡å¼è¾“å‡ºï¼Œå°ºå¯¸æ›´é€‚åˆç»ˆç«¯
        print("è¯·ä½¿ç”¨Bilibiliæ‰‹æœºå®¢æˆ·ç«¯æ‰«æä¸Šæ–¹äºŒç»´ç ç™»å½•...")

        # 3. è½®è¯¢æ‰«ç çŠ¶æ€
        try:
            while True:
                poll_url = f"https://passport.bilibili.com/x/passport-login/web/qrcode/poll?qrcode_key={qrcode_key}"
                resp = self.session.get(poll_url)
                poll_data = resp.json()["data"]
                code = poll_data["code"]
                
                if code == 0:  # 0: ç™»å½•æˆåŠŸ
                    print("\nâœ… æ‰«ç æˆåŠŸ, ç™»å½•æˆåŠŸï¼")
                    self.csrf = self.session.cookies.get("bili_jct")
                    self.save_cookie()
                    break
                elif code == 86038: # 86038: äºŒç»´ç å·²å¤±æ•ˆ
                    print("\nâŒ äºŒç»´ç å·²å¤±æ•ˆ, è¯·é‡æ–°è¿è¡Œç¨‹åºã€‚")
                    exit()
                elif code == 86090: # 86090: å·²æ‰«æå¾…ç¡®è®¤
                    print("æ‰«ææˆåŠŸ, è¯·åœ¨æ‰‹æœºä¸Šç¡®è®¤ç™»å½•...", end='\r')
                # å…¶ä»–çŠ¶æ€ç  (86101:æœªæ‰«æ) åˆ™ç»§ç»­ç­‰å¾…
                
                time.sleep(2)
        except KeyboardInterrupt:
            print("\nğŸš« ç”¨æˆ·å–æ¶ˆç™»å½•ã€‚")
            exit()
    
    def get(self, url: str, **kwargs: Any) -> requests.Response:
        """
        å°è£…äº† requests.get æ–¹æ³•ï¼Œå¹¶å¢åŠ äº†å¯¹ç™»å½•å¤±æ•ˆçš„è‡ªåŠ¨å¤„ç†èƒ½åŠ›ã€‚
        """
        try:
            # é¦–æ¬¡å°è¯•å‘é€è¯·æ±‚
            resp = self.session.get(url, **kwargs)
            resp.raise_for_status() # æ£€æŸ¥ HTTP é”™è¯¯ (å¦‚ 404, 500)
            
            # æ£€æŸ¥Bç«™ä¸šåŠ¡é”™è¯¯ç 
            data = resp.json()
            if data.get("code") == -101: # -101 é€šå¸¸ä»£è¡¨ "è´¦å·æœªç™»å½•"
                raise BiliAuthError("Cookie å·²å¤±æ•ˆ (code: -101)")
            
            return resp

        except BiliAuthError as e:
            print(f"\nâš ï¸ è­¦å‘Š: {e}ã€‚ Cookie å¯èƒ½åœ¨è¿è¡Œä¸­å·²è¿‡æœŸã€‚")
            print("ğŸ”„ æ­£åœ¨å°è¯•é‡æ–°ç™»å½•ä»¥åˆ·æ–° Cookie...")
            
            # è°ƒç”¨æ‰«ç ç™»å½•æµç¨‹æ¥è·å–æ–° Cookie
            self.login_by_qrcode()
            
            # ä½¿ç”¨å…¨æ–°çš„ã€æœ‰æ•ˆçš„ Cookie é‡æ–°å‘é€åˆšæ‰å¤±è´¥çš„è¯·æ±‚
            print("âœ… ç™»å½•æˆåŠŸ! æ­£åœ¨é‡è¯•åˆšæ‰å¤±è´¥çš„è¯·æ±‚...")
            resp = self.session.get(url, **kwargs)
            resp.raise_for_status()
            return resp

# ==============================================================================
# å°†ä¸šåŠ¡é€»è¾‘å‡½æ•°ä¸ Session å®ä¾‹è§£è€¦
# ==============================================================================
def sanitize_filename(filename: str) -> str:
    """å»é™¤æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦"""
    return "".join(c for c in filename if c not in r'\/:*?"<>|')

def get_video_info(bili_session: BiliBiliSession, bvid: str) -> Tuple[int, str, List[Dict]]:
    """æ ¹æ®BVå·è·å–aid, è§†é¢‘ä¸»æ ‡é¢˜, ä»¥åŠæ‰€æœ‰åˆ†Pçš„åˆ—è¡¨"""
    url = f"https://api.bilibili.com/x/web-interface/view?bvid={bvid}"
    resp = bili_session.get(url)
    data = resp.json()
    
    if data["code"] != 0:
        raise RuntimeError(f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {data.get('message', 'æœªçŸ¥é”™è¯¯')}")
    
    view_data = data["data"]
    aid = view_data["aid"]
    title = view_data["title"]
    pages_list = view_data.get("pages", [])
    
    # â˜… å‡çº§ç‚¹ 2: å…¼å®¹å•ä¸ªè§†é¢‘çš„æƒ…å†µ
    # å¦‚æœæ²¡æœ‰pagesåˆ—è¡¨ï¼Œè¯´æ˜æ˜¯å•ä¸ªè§†é¢‘ï¼Œæˆ‘ä»¬æ‰‹åŠ¨æ„å»ºä¸€ä¸ªå’Œå¤šPå…¼å®¹çš„åˆ—è¡¨ç»“æ„
    if not pages_list:
        pages_list = [{
            "cid": view_data["cid"],
            "page": 1,
            "part": title  # å•ä¸ªè§†é¢‘çš„åˆ†Pæ ‡é¢˜å°±æ˜¯ä¸»æ ‡é¢˜
        }]

    return aid, title, pages_list

def process_video_part(
    bili_session: BiliBiliSession, 
    aid: int, 
    page_info: Dict, 
    main_title: str, 
    is_collection: bool, 
    args: argparse.Namespace,
    json_save_dir: Path,
    txt_save_dir: Path
) -> Optional[List[str]]:
    """
    å¤„ç†å•ä¸ªè§†é¢‘åˆ†Pçš„å®Œæ•´æµç¨‹ï¼šè·å–å­—å¹•ã€ä¸‹è½½ã€æå–ã€‚
    
    Args:
        bili_session: Bilibiliä¼šè¯å¯¹è±¡ã€‚
        aid: è§†é¢‘çš„ aidã€‚
        page_info: å•ä¸ªåˆ†Pçš„ä¿¡æ¯å­—å…¸ (åŒ…å« cid, page, part)ã€‚
        main_title: è§†é¢‘çš„ä¸»æ ‡é¢˜ã€‚
        is_collection: æ˜¯å¦ä¸ºåˆé›†ã€‚
        args: å‘½ä»¤è¡Œå‚æ•°ã€‚
        json_save_dir: JSON ä¿å­˜ç›®å½•ã€‚
        txt_save_dir: TXT ä¿å­˜ç›®å½•ã€‚
    """
    cid = page_info["cid"]
    page_num = page_info["page"]
    part_title = page_info["part"]
    
    print("-" * 50)
    if is_collection:
        print(f"â–¶ï¸ æ­£åœ¨å¤„ç† P{page_num}: {part_title}")
    
    sub_url, subtitle_list = get_subtitle_url(bili_session, aid, cid, args.lan)

    if not sub_url:
        print("    âŒ è¯¥åˆ†Pæ²¡æœ‰å¯ç”¨å­—å¹•ã€‚")
        return None # ç›´æ¥è¿”å›Noneï¼Œè¡¨ç¤ºå¤±è´¥

    print("    ğŸ“œ å¯ç”¨å­—å¹•åˆ—è¡¨ï¼š")
    for sub in subtitle_list:
        is_selected = "https:" + sub.get("subtitle_url", "") == sub_url
        prefix = "ğŸ‘‰" if is_selected else "  "
        print(f"     {prefix} {sub['lan']:<8} ({sub['lan_doc']})")
    
    # æ™ºèƒ½ç”Ÿæˆæ–‡ä»¶å
    safe_main_title = sanitize_filename(main_title)
    safe_part_title = sanitize_filename(part_title)
    
    if is_collection and main_title != safe_part_title:
        file_stem = f"P{page_num} {safe_part_title}" # åˆé›†å†…æ–‡ä»¶åæ›´ç®€æ´
    else: # å•ä¸ªè§†é¢‘æˆ–åˆ†Pæ ‡é¢˜ä¸ä¸»æ ‡é¢˜ç›¸åŒæ—¶
        file_stem = safe_main_title

    # ä½¿ç”¨ä¼ å…¥çš„ç›®å½•æ¥æ„å»ºæœ€ç»ˆè·¯å¾„
    json_save_path = json_save_dir / f"{file_stem}.json"
    download_subtitle(bili_session, sub_url, json_save_path)

    # æ ¹æ® --merge å‚æ•°å†³å®šæ˜¯å¦ä¿å­˜å•ä¸ªTXTæ–‡ä»¶
    should_save_individual_file = not (args.merge and is_collection and not args.part)
    if should_save_individual_file:
        txt_output_path = txt_save_dir / f"{file_stem}.txt"
        extract_bilibili_subtitle(json_save_path, txt_output_path)

    with open(json_save_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    lines = [item["content"] for item in data.get("body", []) if "content" in item]
    return lines

# WBI mixinKey ç”Ÿæˆç®—æ³•
def get_mixin_key(img_key: str, sub_key: str) -> str:
    s = img_key + sub_key
    table = [
        46, 47, 18, 2, 53, 8, 23, 32, 15, 50, 10, 31, 58, 3, 45, 35, 27, 43, 5, 49,
        33, 9, 42, 19, 29, 28, 14, 39, 12, 38, 41, 13, 37, 48, 7, 16, 24, 55, 40,
        61, 26, 17, 0, 1, 60, 51, 30, 4, 22, 25, 54, 21, 56, 59, 6, 63, 57, 62, 11,
        36, 20, 34, 44, 52
    ]
    return "".join([s[i] for i in table])[:32]

# WBI ç­¾åå‚æ•°ç¼–ç 
def encode_params(params: Dict[str, Any], mixin_key: str) -> Dict[str, Any]:
    # ç»™å‚æ•°åŠ ä¸Š wts
    params["wts"] = int(time.time())
    # è¿‡æ»¤ç‰¹æ®Šå­—ç¬¦
    for k, v in params.items():
        if isinstance(v, str):
            v = v.replace("!", "").replace("'", "").replace("(", "").replace(")", "").replace("*", "")
            params[k] = v
    params = dict(sorted(params.items()))
    query = urllib.parse.urlencode(params)
    w_rid = hashlib.md5((query + mixin_key).encode()).hexdigest()
    params["w_rid"] = w_rid
    return params

def get_wbi_keys(bili_session: BiliBiliSession) -> Tuple[str, str]:
    """è·å– img_key å’Œ sub_key"""
    resp = bili_session.get("https://api.bilibili.com/x/web-interface/nav") # ä½¿ç”¨ session å¯¹è±¡
    resp.raise_for_status()
    data = resp.json()["data"]["wbi_img"]
    img_key = data["img_url"].split("/")[-1].split(".")[0]
    sub_key = data["sub_url"].split("/")[-1].split(".")[0]
    return img_key, sub_key

def get_subtitle_url(
    bili_session: BiliBiliSession, aid: int, cid: int, lan: Optional[str] = 'ai-zh', retries: int = 3, delay: int = 2
) -> Tuple[Optional[str], list]:
    """ä½¿ç”¨æ–°ç‰ˆ wbi æ¥å£è·å–å­—å¹• URL"""
    img_key, sub_key = get_wbi_keys(bili_session)
    mixin_key = get_mixin_key(img_key, sub_key)

    base_params = {
        "aid": aid,
        "cid": cid,
        "isGaiaAvoided": "false",
        "web_location": "1315873",
    }
    params = encode_params(base_params, mixin_key)

    url = "https://api.bilibili.com/x/player/wbi/v2"
    for attempt in range(1, retries + 1):
        try:
            resp = bili_session.get(url, params=params) # â˜… ä½¿ç”¨ session å¯¹è±¡
            resp.raise_for_status()
            data = resp.json()

            if data["code"] != 0:
                print(f"âš ï¸ API è¿”å›é”™è¯¯: {data['message']}")
                return None, []
            
            subtitles = data["data"]["subtitle"].get("subtitles", [])

            if subtitles:
                if lan:
                    for sub in subtitles:
                        if sub["lan"] == lan and sub.get("subtitle_url"):
                            return "https:" + sub["subtitle_url"], subtitles
                # å¦‚æœæŒ‡å®šè¯­è¨€æ‰¾ä¸åˆ°æˆ–æœªæŒ‡å®šï¼Œè¿”å›ç¬¬ä¸€ä¸ª
                for sub in subtitles:
                    if sub.get("subtitle_url"):
                        return "https:" + sub["subtitle_url"], subtitles

            print(f"âš ï¸ ç¬¬ {attempt} æ¬¡è¯·æ±‚æœªè·å–åˆ°å­—å¹•ï¼Œç­‰å¾… {delay} ç§’é‡è¯•...")
            time.sleep(delay)
        
        except requests.RequestException as e:
            print(f"âŒ ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
            time.sleep(delay)

    return None, []

def create_clickable_link(uri: str, text: str) -> str:
    """
    ä½¿ç”¨ OSC 8 ç»ˆç«¯åºåˆ—åˆ›å»ºå¯ç‚¹å‡»çš„è¶…é“¾æ¥ã€‚
    
    Args:
        uri: é“¾æ¥çš„ç›®æ ‡åœ°å€ (ä¾‹å¦‚ 'file:///C:/path/to/file')ã€‚
        text: è¦åœ¨ç»ˆç«¯ä¸­æ˜¾ç¤ºçš„æ–‡æœ¬ (ä¾‹å¦‚ 'C:\\path\\to\\file')ã€‚

    Returns:
        ä¸€ä¸ªç‰¹æ®Šçš„å­—ç¬¦ä¸²ï¼Œåœ¨å…¼å®¹çš„ç»ˆç«¯ä¸­ä¼šæ˜¾ç¤ºä¸ºè¶…é“¾æ¥ã€‚
    """
    # OSC 8 åºåˆ—æ ¼å¼: \x1b]8;;URI\x1b\\TEXT\x1b]8;;\x1b\\
    # \x1b æ˜¯ ESC å­—ç¬¦
    # \x1b\\ æ˜¯å­—ç¬¦ä¸²ç»ˆæ­¢ç¬¦ (ST)
    return f"\x1b]8;;{uri}\x1b\\{text}\x1b]8;;\x1b\\"

def print_clickable_path(message: str, file_path: Path) -> None:
    """
    æ‰“å°ä¸€æ¡åŒ…å«å¯ç‚¹å‡»æ–‡ä»¶è·¯å¾„çš„æ¶ˆæ¯ã€‚

    è¿™ä¼šåœ¨ç»ˆç«¯ä¸­æ˜¾ç¤ºæ–‡ä»¶çš„å¯è¯»è·¯å¾„ï¼Œä½†é“¾æ¥åˆ°å…¶ URI ç¼–ç ç‰ˆæœ¬ï¼Œ
    ä»è€Œè§£å†³äº†ä¸­æ–‡å’Œç©ºæ ¼è·¯å¾„çš„ç‚¹å‡»é—®é¢˜ã€‚

    Args:
        message: æ‰“å°åœ¨é“¾æ¥å‰çš„å‰ç¼€æ¶ˆæ¯ (ä¾‹å¦‚ "æ–‡ä»¶å·²ä¿å­˜è‡³: ")ã€‚
        file_path: æŒ‡å‘æ–‡ä»¶çš„ Path å¯¹è±¡ã€‚
    """
    abs_path = file_path.resolve()
    uri_target = abs_path.as_uri()
    display_text = str(abs_path)
    
    clickable_output = create_clickable_link(uri_target, display_text)
    print(f"{message}{clickable_output}")

# ä¸‹è½½å’Œæ–‡ä»¶å¤„ç†å‡½æ•°
def download_subtitle(bili_session: BiliBiliSession, sub_url: str, save_path: Path) -> Path:
    """ä¸‹è½½å­—å¹•JSON"""
    resp = bili_session.get(sub_url) # ä½¿ç”¨ session å¯¹è±¡
    resp.raise_for_status()
    save_path.parent.mkdir(parents=True, exist_ok=True)
    save_path.write_text(resp.text, encoding="utf-8")
    
    print_clickable_path("ğŸ’¾ JSON å·²ä¿å­˜è‡³ ", save_path)
    return save_path

def extract_bilibili_subtitle(json_path: Path, output_path: Path):
    """ä»å­—å¹•JSONæå–æ–‡æœ¬å¹¶ä¿å­˜"""
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    lines = [item["content"] for item in data.get("body", []) if "content" in item]

    output_path.write_text("\n".join(lines), encoding="utf-8")
    
    print_clickable_path("âœ… å­—å¹•å·²æå–å®Œæˆ ", output_path)

# ==============================================================================
# ä¸»å‡½æ•°
# ==============================================================================

def main():
    parser = argparse.ArgumentParser(description="è¾“å…¥BVå·ï¼Œè‡ªåŠ¨ä¸‹è½½å¹¶æå–Bç«™å­—å¹•ï¼ˆå…¼å®¹æœ€æ–°APIï¼‰")
    parser.add_argument("bvid", help="è§†é¢‘çš„BVå· (å•ä¸ªè§†é¢‘æˆ–åˆé›†å‡å¯)")
    parser.add_argument("-o", "--output", default="output", help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ output/ï¼‰")
    parser.add_argument("--json-dir", default="input", help="åŸå§‹JSONä¿å­˜ç›®å½•ï¼ˆé»˜è®¤ input/ï¼‰")
    parser.add_argument("--lan", help="å­—å¹•è¯­è¨€ä»£ç ï¼Œä¾‹å¦‚ zh-CN, en-US, ai-zh ç­‰")
    parser.add_argument("-p", "--part", type=int, help="æŒ‡å®šè¦æå–çš„å•ä¸ªåˆ†Pç¼–å· (ä¾‹å¦‚: -p 5)")
    parser.add_argument("--merge", action="store_true", help="å°†å¤šPåˆé›†çš„å­—å¹•åˆå¹¶è¾“å‡ºåˆ°ä¸€ä¸ªTXTæ–‡ä»¶ä¸­ (ä»…å¯¹å¤„ç†æ•´ä¸ªåˆé›†æ—¶æœ‰æ•ˆ)"
    )
    args = parser.parse_args()

    # å®ä¾‹åŒ–å¹¶åˆå§‹åŒ– Session
    try:
        bili_session = BiliBiliSession()
        
        print(f"\nğŸ“„ æ­£åœ¨è·å–è§†é¢‘ä¿¡æ¯: {args.bvid}")
        aid, main_title, pages_list = get_video_info(bili_session, args.bvid)

        # æ ¹æ® --part å‚æ•°ç­›é€‰è¦å¤„ç†çš„åˆ†Påˆ—è¡¨
        target_pages_list = pages_list
        if args.part:
            # ä»å…¨éƒ¨åˆ†Påˆ—è¡¨ä¸­æŸ¥æ‰¾ç”¨æˆ·æŒ‡å®šçš„é‚£ä¸€P
            found_part = next((p for p in pages_list if p['page'] == args.part), None)
            if found_part:
                target_pages_list = [found_part] # å°†ç›®æ ‡åˆ—è¡¨ç¼©å‡ä¸ºä»…å«æŒ‡å®šçš„é‚£ä¸€P
                print(f"âœ… å·²æŒ‡å®šæå– P{args.part}ã€‚")
            else:
                print(f"âŒ é”™è¯¯: åˆ†På· {args.part} ä¸å­˜åœ¨ã€‚è¯¥è§†é¢‘å…±æœ‰ {len(pages_list)} ä¸ªåˆ†Pã€‚")
                return # æ‰¾ä¸åˆ°æŒ‡å®šåˆ†Pï¼Œç›´æ¥é€€å‡º

        is_collection = len(pages_list) > 1
        # æ ¹æ®æ˜¯å¦ä¸ºåˆé›†ï¼Œå†³å®šæœ€ç»ˆçš„è¾“å‡ºç›®å½•
        base_dir = Path(__file__).resolve().parent
        safe_main_title = sanitize_filename(main_title)
        # é»˜è®¤è¾“å‡ºç›®å½•ä¸ºæ ¹ç›®å½•
        json_output_dir = base_dir / args.json_dir
        txt_output_dir = base_dir / args.output
        if is_collection and not args.part: # ä»…åœ¨å¤„ç†æ•´ä¸ªåˆé›†ä¸”ä¸åˆå¹¶æ—¶æ˜¾ç¤ºæ­¤ä¿¡æ¯å¹¶åˆ›å»ºæ–‡ä»¶å¤¹
            json_output_dir = json_output_dir / safe_main_title
            if not args.merge:
                txt_output_dir = txt_output_dir / safe_main_title
            print(f"åˆé›†æ ‡é¢˜: {main_title}")
            print(f"åˆé›†åŒ…å« {len(pages_list)} ä¸ªåˆ†Pã€‚")
        elif is_collection and args.part: # å¤„ç†åˆé›†çš„å•ä¸ªPæˆ–åˆå¹¶
            print(f"åˆé›†æ ‡é¢˜: {main_title}")
        else:
            print(f"è§†é¢‘æ ‡é¢˜: {main_title}")

        all_subtitle_lines = []

        for page_info in target_pages_list:
            returned_lines = process_video_part(
                bili_session, aid, page_info, main_title, is_collection, args,
                json_output_dir, txt_output_dir
            )
            
            # å°†è¿”å›çš„å­—å¹•è¡Œå’Œåˆ†éš”ç¬¦æ·»åŠ åˆ°ä¸»åˆ—è¡¨ä¸­
            if returned_lines:
                part_title = page_info["part"]
                page_num = page_info["page"]
                separator = f"\n\n--- P{page_num} {part_title} ---\n\n"
                
                if all_subtitle_lines: # é¿å…åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ åˆ†éš”ç¬¦
                    all_subtitle_lines.append(separator)
                
                all_subtitle_lines.extend(returned_lines)
            
            time.sleep(1)

        # å¾ªç¯ç»“æŸåï¼Œæ ¹æ® --merge å‚æ•°æ‰§è¡Œåˆå¹¶å†™å…¥æ“ä½œ
        if args.merge and is_collection and not args.part and all_subtitle_lines:
            merged_filename = f"{safe_main_title} (å®Œæ•´å­—å¹•).txt"
            merged_output_path = txt_output_dir / merged_filename
            
            merged_output_path.parent.mkdir(parents=True, exist_ok=True)
            merged_output_path.write_text("".join(all_subtitle_lines), encoding="utf-8")
            
            print("-" * 50)
            print_clickable_path("âœ… æ‰€æœ‰åˆ†På­—å¹•å·²æˆåŠŸåˆå¹¶è‡³: ", merged_output_path)

    except (requests.RequestException, RuntimeError, KeyError) as e:
        print(f"\nğŸ’¥ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­æ“ä½œ, ç¨‹åºé€€å‡ºã€‚")


if __name__ == "__main__":
    main()