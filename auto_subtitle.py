import requests
import json
import os
import argparse
import time
import hashlib
import urllib.parse

from pathlib import Path


HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                  "AppleWebKit/537.36 (KHTML, like Gecko) "
                  "Chrome/114.0.0.0 Safari/537.36",
    "Referer": "https://www.bilibili.com/",
}


# ä»¥è„šæœ¬æ–‡ä»¶æ‰€åœ¨ç›®å½•ä¸ºåŸºå‡†ï¼Œé¿å…å— CWD å½±å“
BASE_DIR = Path(__file__).resolve().parent


def load_cookie(cookie_file="cookie.txt"):
    """ä»æ–‡ä»¶è¯»å– cookie"""
    cookie_path = BASE_DIR / cookie_file
    if not cookie_path.exists():
        print("âš ï¸ æ²¡æ‰¾åˆ° cookie.txtï¼Œç»§ç»­ä½¿ç”¨æ¸¸å®¢æ¨¡å¼ï¼ˆå¯èƒ½æ²¡æœ‰å­—å¹•ï¼‰")
        return None
    return cookie_path.read_text(encoding="utf-8").strip()


cookie = load_cookie()
if cookie:
    HEADERS["Cookie"] = cookie


def get_aid_cid_and_title(bvid):
    """æ ¹æ®BVå·è·å–aid, cidå’Œè§†é¢‘æ ‡é¢˜"""
    url = f"https://api.bilibili.com/x/web-interface/view?bvid={bvid}"
    resp = requests.get(url, headers=HEADERS)
    resp.raise_for_status()
    data = resp.json()
    aid = data["data"]["aid"]
    cid = data["data"]["cid"]
    title = data["data"]["title"]
    # å»æ‰æ–‡ä»¶åä¸­ä¸å…è®¸çš„å­—ç¬¦
    title = "".join(c for c in title if c not in r'\/:*?"<>|')
    return aid, cid, title


# WBI mixinKey ç”Ÿæˆç®—æ³•
def get_mixin_key(img_key, sub_key):
    s = img_key + sub_key
    table = [46, 9, 25, 3, 28, 17, 46, 0, 8, 7, 12, 18, 1, 4, 45, 6,
             31, 43, 10, 11, 2, 19, 16, 44, 13, 5, 32, 34, 24, 29,
             36, 26, 38, 15, 23, 37, 22, 27, 35, 30, 21, 41, 20,
             42, 39, 14, 33, 40]
    return "".join([s[i] for i in table])[:32]


def encode_params(params, mixin_key):
    # ç»™å‚æ•°åŠ ä¸Š wts
    params["wts"] = int(time.time())
    # è¿‡æ»¤ç‰¹æ®Šå­—ç¬¦
    for k, v in params.items():
        if isinstance(v, str):
            params[k] = v.replace("!", "").replace("'", "").replace(
                "(", "").replace(")", "").replace("*", "")
    # æ’åº
    params = dict(sorted(params.items()))
    query = urllib.parse.urlencode(params)
    # ç”Ÿæˆ w_rid
    w_rid = hashlib.md5((query + mixin_key).encode()).hexdigest()
    params["w_rid"] = w_rid
    return params


def get_wbi_keys():
    """è·å– img_key å’Œ sub_key"""
    resp = requests.get(
        "https://api.bilibili.com/x/web-interface/nav", headers=HEADERS)
    resp.raise_for_status()
    data = resp.json()["data"]["wbi_img"]
    img_key = data["img_url"].split("/")[-1].split(".")[0]
    sub_key = data["sub_url"].split("/")[-1].split(".")[0]
    return img_key, sub_key


def get_subtitle_url(aid, cid, lan='ai-zh', retries=3, delay=2):
    """ä½¿ç”¨æ–°ç‰ˆ wbi æ¥å£è·å–å­—å¹• URL"""
    img_key, sub_key = get_wbi_keys()
    mixin_key = get_mixin_key(img_key, sub_key)

    base_params = {
        "aid": aid,
        "cid": cid,
        "isGaiaAvoided": "false",
        "web_location": "1315873",
    }
    params = encode_params(base_params, mixin_key)

    url = "https://api.bilibili.com/x/player/wbi/v2"
    for attempt in range(1, retries + 1):
        resp = requests.get(url, headers=HEADERS, params=params)
        resp.raise_for_status()
        data = resp.json()
        subtitles = data["data"]["subtitle"].get("subtitles", [])
        # subtitles = data.get("data", {})["subtitle"].get("subtitles", [])

        if subtitles:
            if lan:
                for sub in subtitles:
                    if sub["lan"] == lan and sub.get("subtitle_url"):
                        return "https:" + sub["subtitle_url"], subtitles
            for sub in subtitles:
                if sub.get("subtitle_url"):
                    return "https:" + sub["subtitle_url"], subtitles

        print(f"âš ï¸ ç¬¬ {attempt} æ¬¡è¯·æ±‚æœªè·å–åˆ°å­—å¹•ï¼Œç­‰å¾… {delay} ç§’é‡è¯•...")
        time.sleep(delay)

    return None, []


def download_subtitle(sub_url, save_dir: Path, save_name: str="subtitle.json"):
    """ä¸‹è½½å­—å¹•JSON"""
    resp = requests.get(sub_url, headers=HEADERS)
    resp.raise_for_status()
    save_dir.mkdir(parents=True, exist_ok=True)   # ç¡®ä¿ç›®å½•å­˜åœ¨
    save_path = save_dir / save_name              # ç”¨ Path ç»„åˆè·¯å¾„
    save_path.write_text(resp.text, encoding="utf-8")
    print(f"ğŸ’¾ JSON å·²ä¿å­˜è‡³: {save_path.resolve()}")  # â˜…ä¿®æ”¹ï¼šæ‰“å°ç»å¯¹è·¯å¾„
    return str(save_path)


def extract_bilibili_subtitle(json_file, output_dir="output"):
    """ä»å­—å¹•JSONæå–æ–‡æœ¬å¹¶ä¿å­˜"""
    with open(json_file, "r", encoding="utf-8") as f:
        data = json.load(f)

    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    base_name = os.path.splitext(os.path.basename(json_file))[0]
    output_file = os.path.join(output_dir, f"{base_name}.txt")

    lines = []
    if "body" in data:
        for item in data["body"]:
            if "content" in item:
                lines.append(item["content"])

    with open(output_file, "w", encoding="utf-8") as f:
        f.write("\n".join(lines))

    print(f"âœ… å­—å¹•å·²æå–å®Œæˆ: {output_file}")


def main():
    parser = argparse.ArgumentParser(description="è¾“å…¥BVå·ï¼Œè‡ªåŠ¨ä¸‹è½½å¹¶æå–Bç«™å­—å¹•ï¼ˆå…¼å®¹æœ€æ–°APIï¼‰")
    parser.add_argument("bvid", help="è§†é¢‘çš„BVå·")
    parser.add_argument("-o", "--output", default="output",
                        help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ output/ï¼‰")
    parser.add_argument("--json-dir", default="input", 
                        help="åŸå§‹JSONä¿å­˜ç›®å½•ï¼ˆé»˜è®¤ input/ï¼‰")
    parser.add_argument("--lan", help="å­—å¹•è¯­è¨€ä»£ç ï¼Œä¾‹å¦‚ zh-CN, en, ai-zh ç­‰")
    args = parser.parse_args()

    bvid = args.bvid
    aid, cid, title = get_aid_cid_and_title(bvid)
    sub_url, subtitle_list = get_subtitle_url(aid, cid, args.lan)

    if not sub_url:
        print("âŒ è¯¥è§†é¢‘æ²¡æœ‰å­—å¹•ï¼ˆæˆ–éœ€è¦ç™»å½•çŠ¶æ€ï¼‰")
        return

    print("ğŸ¬ å¯ç”¨å­—å¹•åˆ—è¡¨ï¼š")
    for sub in subtitle_list:
        print(f"  {sub['lan']} - {sub['lan_doc']}")

    print(f"ğŸ‘‰ é€‰æ‹©çš„å­—å¹•åœ°å€: {sub_url}")
    json_dir = (BASE_DIR / args.json_dir)          # json ç›®å½•å›ºå®šåˆ°è„šæœ¬ç›®å½•
    json_file = download_subtitle(sub_url, json_dir, f"{title}.json")
    extract_bilibili_subtitle(json_file, args.output)


if __name__ == "__main__":
    main()
